{
  "id": "36782ca08a06a5ef",
  "title": "Taalas serves Llama 3.1 8B at 17,000 tokens/second",
  "url": "https://simonwillison.net/2026/Feb/20/taalas/#atom-everything",
  "content": "<p><strong><a href=\"https://taalas.com/the-path-to-ubiquitous-ai/\">Taalas serves Llama 3.1 8B at 17,000 tokens/second</a></strong></p>\nThis new Canadian hardware startup just announced their first product - a custom hardware implementation of the Llama 3.1 8B model (from <a href=\"https://simonwillison.net/2024/Jul/23/introducing-llama-31/\">July 2024</a>) that can run at a staggering 17,000 tokens/second.</p>\n<p>I was going to include a video of their demo but it's so fast it would look more like a screenshot. You can try it out at <a href=\"https://chatjimmy.ai\">chatjimmy.ai</a>.</p>\n<p>They describe their Silicon Llama as “aggressively quantized, combining 3-bit and 6-bit parameters.” Their next generation will use 4-bit - presumably they have quite a long lead time for baking out new models!\n\n    <p><small></small>Via <a href=\"https://news.ycombinator.com/item?id=47086181\">Hacker News</a></small></p>\n\n\n    <p>Tags: <a href=\"https://simonwillison.net/tags/ai\">ai</a>, <a href=\"https://simonwillison.net/tags/generative-ai\">generative-ai</a>, <a href=\"https://simonwillison.net/tags/llama\">llama</a>, <a href=\"https://simonwillison.net/tags/llms\">llms</a></p>"
}